{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Interactive textgenrnn Demo w/ GPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihyun0092/text/blob/master/Copy_of_Interactive_textgenrnn_Demo_w_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "#  Interactive textgenrnn Demo w/ GPU\n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: December 2nd, 2018*\n",
        "\n",
        "Generate text using a pretrained neural network with a few lines of code, or easily train your own text-generating neural network of any size and complexity, **for free on a GPU using Collaboratory!**\n",
        "\n",
        "For more about textgenrnn, you can visit [this GitHub repository](https://github.com/minimaxir/textgenrnn).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes.\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "outputId": "bee74be7-0ccc-4336-c9d6-94812846a64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!pip install -q textgenrnn\n",
        "%tensorflow_version 1.x\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "source": [
        "Set the textgenrnn model configuration here: the default parameters here give good results for most workflows. (see the [demo notebook](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about these parameters)\n",
        "\n",
        "If you are using an input file where documents are line-delimited, make sure to set `line_delimited` to `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "source": [
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any text file** and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"feed.txt\"\n",
        "model_name = 'colaboratory' # change to set file name of resulting trained models/texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "The next cell will start the actual training. And thanks to the power of Keras's CuDNN layers, training is super-fast when compared to CPU training on a local machine!\n",
        "\n",
        "Ideally, you want a training loss less than `1.0` in order for the model to create sensible text consistently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "outputId": "d8037bf9-020f-43af-fd89-38166214e15a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training new model w/ 3-layer, 128-cell LSTMs\n",
            "Training on 3,499,189 character sequences.\n",
            "Epoch 1/20\n",
            "3417/3417 [==============================] - 262s 77ms/step - loss: 2.8396\n",
            "Epoch 2/20\n",
            "3417/3417 [==============================] - 261s 76ms/step - loss: 2.3378\n",
            "Epoch 3/20\n",
            "3417/3417 [==============================] - 261s 76ms/step - loss: 2.2357\n",
            "Epoch 4/20\n",
            "3417/3417 [==============================] - 260s 76ms/step - loss: 2.1791\n",
            "Epoch 5/20\n",
            "3417/3417 [==============================] - 263s 77ms/step - loss: 2.1394\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "은 그 사람이 아니었다고 말했어요\"\n",
            "“그 애들은 그 사람이 아니었어요. 그 사람은 그녀의 아버지의 아들이 아니었지만， 그 사람은 그녀가 그 사실을 알고 있었다. 그녀는 그녀를 보고 말했다.\n",
            "“그 애들은 그 사람이 아니었어요. 그 사람은 그 사람이 아니었지만 그녀는 그 사실을 알고 있었다. 그녀는 그녀를 보고 말했다.\n",
            "“그 사람은 그 사람이 아니었어요. 그 애들은 내 아들이 아니었다. 그녀는 그녀를 보고 말을 타고 가는 동안 그녀를 따라 그녀를 보고 싶었다.\n",
            "“그 사람은 그 사람이 아니었지만 그녀는 그 사실을 알고 있었다. 그녀는 그\n",
            "\n",
            "어요\"\n",
            "“그 사람은 그 사람이 아니었어요. 그 애들은 그 사람이 아니었다고 말했어요. 그 애들은 그 사람이 아니었지만， 그 사람은 그녀가 그녀를 아주 잘 알고 있었다. 그녀는 그녀를 보고 말했다.\n",
            "“그 사람은 그 사람이 아니었어요. 그 사람은 그 사람이 아니었다고 말했어요. 그 사람은 그녀의 아버지가 아니었지만， 그녀는 그 사실을 알고 있었다.\n",
            "“그 애들은 그 사람이 아니었다고 생각하지 않았어요. 그 아이는 그 사람이 아니었다고 말했어요. 그는 그녀를 보고 싶었지만 그녀는 그녀를 보고 싶었다.\n",
            "“그 사람은 그 사람이 아니었다고 말했\n",
            "\n",
            "다. 그녀는 그녀의 아버지의 아들이었다. 그녀는 그녀의 아버지의 아버지와 함께 있었다. 그녀는 그녀를 그 자리에 있었다. 그녀는 그녀를 그 자리에 있었다. 그녀는 그녀가 그녀를 보고 싶었다.\n",
            "“그 사람은 그 사람이 아니었어요. 그 사람이 그 사실을 알고 있는 것이 아니었다. 그녀는 그녀를 보고 말했다.\n",
            "“그 사람은 그 사람이 아니었어요. 그 애들은 그 사람이 그 사실을 알고 있었다. 그 사실은 그녀가 그녀를 보고 싶었다.\n",
            "“그 사람은 그 사람이 아니었어요\"\n",
            "“그 사람은 그 사람이 아니었어요. 그녀는 그 사람이 아니었지만 그녀는 자신\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "이야.’\n",
            "그녀는 아리아가 그 사실을 알고 있었다.\n",
            "‘그는 아직도 그녀가 그 자리를 찾고 있었다.\n",
            "“그 소년은 그녀에게 반드시 말을 타고 있었던 것이다. 그녀는 그녀의 동생을 그의 목에서 올라탔다. 그녀는 그녀가 그녀를 붙잡고 있었다. 그들은 그녀를 기다리고 있었다.\n",
            "\n",
            "‘그 앤 자이메는 그 녀의 딸을 대신해 싸우겠어.’\n",
            "그녀는 그녀를 대신하고 있었다.\n",
            "“그녀는 그 애인 부인과 함께 온 것을 알고 있었다. 그는 그 곳에서 그를 위해 모든 것을 알 수 있었다. 그는 그의 아버지가 그녀를 거부하고 있는 것을 알고 있었다. 그녀는 자신의 아\n",
            "\n",
            "그녀를 내버려두었다.\n",
            "“그들은 뒤에서 그의 옆에 도착했을 때 의자를 가지고 있었다. 그녀는 그 사실을 알아차렸다. 그는 그녀를 다시 이끌고 있었다. 이제 그는 그녀를 아주 잘 알아보지 못한 것을 지켜보았다. \"하지만 당신은 죽음을 당했어요.\" \n",
            "\n",
            "\"그렇게 하지 않았습니다. 제가 자신의 자리를 돌려 주십시오. 그리고 이제는 아무 소용이 없었습니다. 하지만 그런 것을 기억하시죠. 그는 당신의 아버지에게 제 아버지를 절대 잊지 못했다. 그녀는 그 사실을 알고 있었다.\n",
            "“그러면 난 그녀를 찾고 있었어요. 그는 그들을 데리고 온 것이 아니었\n",
            "\n",
            ". 그녀는 그녀의 형제들을 보고 그를 따라왔지만 그녀는 그 어느 일이었다. 그녀는 그 의자에서 그녀를 그에게 맞이하는 것을 알고 있었다. 그녀는 그녀가 그녀를 그 자리에 앉았다.\n",
            "“그 사람이 아니라 그 사람은 그 기사에게 이렇게 고집했다. 아무리 그 어느 남자가 그에게 미소를 지었다.\n",
            "\"그리고 그 이름이 알지 못했다. 그 애는 내가 너무 위험해 보였다. 그는 그녀를 위해 그 사실을 알고 있었다. 그녀는 그녀의 아버지의 기도를 들었고， 그 애들은 그 일을 저지른 일에 대해 알고 있었다. 그는 그녀를 억지로 끌어내려 그녀를 밀어냈다.\n",
            "\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "이 생기는 거지?\n",
            "살로스 부인은 외로움이 없고， 검은 별명이 있었다. 타기엔 거기서 하룻밤을 없애쓰라고 소리치켜 놓아야 하다\"\n",
            "그랜디슨이 다시 하고 싶었다.\n",
            "“포드릭콘은 마법을 가르고 싶었네\"\n",
            "그 여자는 그녀에게 솔직히 고집스레도 아들이었다. 그의 아버지는 아버지의 하녀와 인사해야 한다는 것을 아기는 아름다움이 들었습니다. 만약 내가 인길을 듣기를 원했지만 슬레이어, 아니면, 영원히 지나갈 셈이네. 만약 너희를 반대할 때, 저들은 모두 조프리레 경세상처럼 날 터뜨릴 것이었다. 돈토스가 살로 공터 범했을 때처럼 가능할 수 없는 일이었\n",
            "\n",
            "침대를 뿌리 없었고, 둘 다 그의 의자는 절대 시지 않았지만, 그녀에게는 아무리 생각을 꾸누하지 않았다.\n",
            "\"오늘 남쪽에서 우리의 칼든 형제들에게 새하게 검을 전신은 토로르 까부터 남은데, 이 곳에한 일 하룻밤이나 용들은 자신의 이름을 망치를 내리쳤다. 했던 길은 매우 때낮이었고.\n",
            "‘용감한물론’ “\n",
            "자기편에‘이그리라불리오!’\n",
            "그녀는사실에 불투하지 않았다.\n",
            "욕이 좀꺼져서\n",
            "너한태 있을 때도 오걀 많은 가마귀를 그 안으로 단순히 범벅이 마에요.\"\n",
            "\n",
            "\"그래도 당신 역시 다시 빙글려 주길 원하니?\"\n",
            "\n",
            "\"아니, 나는 그냥 무슨 거죠?\"\n",
            "  \"그\n",
            "\n",
            "이 있었지만， 대니는생긴 자신의 든상인이었다.\n",
            "“그렇게 하시는 자. 거기 할말야고 산사 자신의 곰과 함께 공주가되는 요리에서는 공손하고 우두머리 사냥을 챙겨놓지요. 스파이크로 명예를 끌었을 때 그대는 기프하고 절대 알 수 없는 모든 사실을 새겨요. 너희미 이름이 모든 것들을 일으켜 \n",
            "왔죠. 연어로 싸는 황결은 널 위해서 시내를 여왕폐했다.\n",
            "\n",
            "아리아는 상냥하게 얼굴이 일었다.\n",
            "\n",
            "\"에다드 경에게는 얼마 살 고 익은 것들이 찾기가 해요. 스타니스 왕도 함락한 사람일곱신 상태가 사실이었겠지. 그들의 영주가 한 맹세를 범하라고\n",
            " 모조리 배신\n",
            "\n",
            "Epoch 6/20\n",
            "3417/3417 [==============================] - 258s 75ms/step - loss: 2.1089\n",
            "Epoch 7/20\n",
            "3417/3417 [==============================] - 264s 77ms/step - loss: 2.0829\n",
            "Epoch 8/20\n",
            "3417/3417 [==============================] - 270s 79ms/step - loss: 2.0607\n",
            "Epoch 9/20\n",
            "3417/3417 [==============================] - 265s 77ms/step - loss: 2.0405\n",
            "Epoch 10/20\n",
            "3417/3417 [==============================] - 265s 77ms/step - loss: 2.0215\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "했다. 그녀는 그녀의 아버지의 아들 중 하나였다. 그녀는 그녀의 아버지가 그녀의 아버지의 손을 잡아당겼다. \"그녀가 그녀의 아버지를 죽였어요. 그녀는 그녀의 아버지의 아들을 낳았다. 그녀는 그녀의 아버지가 그녀의 아버지를 죽였었다. 그녀는 그녀의 아버지가 그녀를 죽였다. 그녀는 그녀의 손가락을 잡아당겼다. 그녀는 그녀의 손에 들려 있었다. 그녀는 그녀의 아버지가 그녀의 손을 잡아당겼다. \"난 그 녀석을 죽이고 싶어. 그러면 그녀가 그녀를 죽였을 때 그녀가 그녀의 아버지가 그녀의 아버지를 죽였다. \n",
            "\n",
            "\"그녀는 그녀를 죽였어요. 그녀가\n",
            "\n",
            " 죽였어. 그녀의 아버지가 그녀의 아버지가 그녀의 아버지를 죽였다. \n",
            "\n",
            "\"그건 그렇지 않아. 난 그 아이를 낳을 수 있을 거라 생각했다. 그녀는 그들을 위해 그녀를 찾아 보였다. 그녀는 그녀의 손에 들려 있었다. 그녀는 그녀의 손가락을 잡아당겼다. \"난 그녀를 죽였어. 그녀가 내 아버지를 죽였어. 그녀는 그녀의 아버지가 그녀를 죽였어. 그녀는 그녀의 아버지가 그녀의 아버지를 죽였어. 그녀는 그녀의 아버지가 그녀의 아버지를 죽였어. 그녀는 그녀의 아버지가 그녀의 아버지를 죽였어. 그녀는 그녀의 아버지가 그녀의 아버지가 그 아이의 아버\n",
            "\n",
            "을 죽였다. 그녀는 그녀의 아버지가 그 애를 죽였을 때 그녀의 아버지가 그녀를 죽였다는 것을 알고 있었다. \n",
            "\n",
            "\"그건 아니야. 그가 어떻게 그런 짓을 하는지 알아?\" \n",
            "\n",
            "\"그건 그렇지 않아. 그리고 그 아이는 그렇게 하지 않을 거야.' 그녀는 그녀의 손가락을 잡아당겼다. \"그녀가 그녀의 아버지를 죽였어요. 그녀는 그녀의 아버지가 그 애를 죽였어요. 그녀는 그녀의 아버지가 그녀에게 그녀를 죽였다는 것을 알고 있었다. 그녀는 그녀의 아버지가 그녀의 아버지를 죽였다. 그녀는 그녀의 아버지가 그녀의 아버지를 죽였다. 그녀는 그녀에게 그녀의\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\n",
            "\n",
            "\"아뇨, 그는 그 자리에 있었어요. 그 애는 당신이 이토록 기뻐하는 거예요. 그녀의 아버지께선 그 아이를 낳을 수 있을 거라고 생각했다.\n",
            "\n",
            "\"하지만 그 대가 우리 가문의 적이 있고, 그 음식은 그들을 가지고 있어요. 그들은 그 소녀에게 자신의 딸을 내려다보고 있었다고 말했었다. 그녀의 아내 부인은 그녀의 아버지가 그녀를 그토록 해주었다. 그녀가 그녀에게 물었던 그녀의 머리를 가슴팍에 가져다 주었다. \n",
            "\n",
            "\"그건 다른 사람들이 있을 거라고 맹세했다. 그러나 그는 에드무레의 아들 롭 스타크에게 그런 주인을 위해 할 의무를 주었을 때,\n",
            "\n",
            "갑판 위에 말을 달렸다. 그러나 그는 그들이 그 이름을 떠올리 말았다. 그녀가 그를 내려다보며 그녀의 다리를 밀어 넣었다. \"난 그건 아니었어. 그 여자가 아니었어. 그 여자는 너 같은 사람이라고 했다. 그는 그 소년의 얼굴을 보았다. \"난 이 곳의 길을 갈 수 있을 거야. 그녀가 이 성을 나가 있을 때 그녀가 그녀의 죽음을 떠올렸다. \"난 그 여자를 찾아야 해요. 그 말이 옳았어요.\" \n",
            "\n",
            "\"그러면 그렇게 되지는 않겠지, 안 그러면 그가 아버지의 아버지를 죽였을 때 그 누구도 그렇게 했을 것이다. 그녀는 그녀의 아버지가 결혼하고 있\n",
            "\n",
            "그녀의 가슴을 내려다보고 있었다. 그녀가 그 이야기를 들었던 곳으로 돌아왔다. \n",
            "\n",
            "'그는 이 곳에서 자이메를 해칠 생각이었다. '내가 원하는 것은 아니야.' 그녀는 그녀의 팔에 입을 맞추었다. \n",
            "\n",
            "\"그렇다면 그녀는 그의 아버지가 아니었어. 그들이 그의 아들이 그녀의 어머니의 머리를 가지고 있었다. 그녀는 그녀의 다리 사이에 앉아 있었다. 그녀의 동료 한 명은 수백 개의 검은 머리를 가리고 있었다. '죽은 자들을 보내 자이메가 그 곳에 있는 것을 알아차렸다. \n",
            "\n",
            "\"그러면 나와 같이 있어.\" \n",
            "\n",
            "\"여덟 사람이 없다,\" 하고 그가 말했다\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            " 섰고， 여름의 젖먹은 짙은 표시\n",
            "였다. 하지만 그녀는 세르세이의 목책 통로에 진 검을 집어들었고 더러운 \n",
            "굴리사이기도 했다. 장대가 식탁 나를 막아 투구 바깥쪽으로 몸을 기울였다. '마을 아이의 홀과 영주님은 어디에 있지?' \n",
            "\n",
            "잠시나마, 머리는 몰물없이 보였고, 이 훌륭한 순간이 자신의 섬들과 함께 춤을 추면 임부들 중 그녀를 완강해범한 문장을 가로질러야 했고 그물 때문에\n",
            "다시 투구를 해야 했다. 추들 모래에 누워 있는 세 걸음 진군함시티 함께 있었다. \n",
            "'이런 결투에 암살했던 '설령 그렇게 부세하지 않으려고 하는 편이 우리 얼\n",
            "\n",
            "그런데 어떤 극사 지하의 다른 하이셉톤크기든 존은 침입자를 뚫어지듯 한숨을 내쉬었다. 그의 눈이 검은 머리카락을 물어뜯혔다. \"저는 혜성을 아닌다고 부르단 말이야. 그녀는 내가 취해서 내가 쓰고 없어진다고 밑바람에 비싸친 잠시 파리의 의견을 다시 일으켰다.\n",
            "[고소를 말씀드리라는 걸 침대에 놓아주겠습니다.]\n",
            "대니는 어차피 아침에 바닥에 피치를 핥고 있는 아크센의 앞에 창의 향긴 기색의 그림자가 나도 모르게 말고기 몇 사람을 돌아보았다.\n",
            "\n",
            "\"아가씨께서 기다리고 있으려 했는데도 당분간 적당하다고 하셨어요. 그는 그 아이를 가지 않아. 브\n",
            "\n",
            " 발견하다가 버려. 거머로 계속 성을 올려 불을 지피시군요.\"\n",
            "[잘라 우리에게 입보다는 손을 잘라 주면 그들은 사람들을 떼어놓고 시간을 \n",
            "갖고 싶어했다. 브론이 자신을 탁자 위의 바라보았다, \"그녀를 보낸 적이 있어,\" 그녀가 대답했다. \n",
            "\n",
            "\"느꼈던 장면도 그쳤어요. 전투는 잘 알고 도와 주는 건 큰만 무슨 이점 없이 귀족 출신처럼 살 만지능에 단검도 다이어울프였다. 허겁지자 부이진 두손을 붙잡고 돌을 발로 들어올려졌다. 수많은 기사가 이 고기를 뒤에 떠는 낮을 당장했으며, 그녀 같은 호치룬이 조롱하게 꾸미는 음료 사이로 인해 앉아\n",
            "\n",
            "Epoch 11/20\n",
            "3417/3417 [==============================] - 258s 76ms/step - loss: 2.0036\n",
            "Epoch 12/20\n",
            "3417/3417 [==============================] - 261s 77ms/step - loss: 1.9863\n",
            "Epoch 13/20\n",
            "3417/3417 [==============================] - 264s 77ms/step - loss: 1.9698\n",
            "Epoch 14/20\n",
            "3417/3417 [==============================] - 264s 77ms/step - loss: 1.9532\n",
            "Epoch 15/20\n",
            "3417/3417 [==============================] - 262s 77ms/step - loss: 1.9368\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            " 있었다. 그는 그들에게 그 말을 듣고 있는 것이 아니라는 사실을 알고 있었다. 그녀는 그녀의 아버지가 그녀를 위해 그녀를 죽였어야 했어.’\n",
            "“그녀는 그 애가 그 애를 죽였어요. 그 애가 그 사람을 보내 주겠어요. 그 사람은 그 사람이 아니에요. 그리고 그 애가 당신의 아들을 보내 주셨어요. 그리고 그 사람은 그 사람이 아니에요. 그들은 그 사람이 아니라고 말씀하셨어요. 그 애는 그의 아들이 아니에요. 그분은 그 애가 아니에요. 그 애가 그 애를 죽였어요. 그 애가 그녀를 죽이려고 하는 것을 알게 될 거예요. 그 애는 그 애를 죽이\n",
            "\n",
            "을 죽이려고 했어요. 그녀는 그 사람을 죽이고 싶지 않았다고 말씀드렸어요. 그 애가 그녀를 죽였어요. 그녀는 그 아이를 보내셨어요. 그녀는 그녀를 죽이고 싶지 않아요. 그녀는 그녀를 위해 그녀를 죽이고 싶어요. 그 애가 그녀를 죽여버렸다고 말했어요. 그녀는 그녀의 아버지를 위해 그녀를 죽이지 않았다. 그녀는 그녀의 아버지가 그녀를 보고 그녀를 알아보지 못했다. 그녀는 그녀의 손에 들려 있는 것을 보았다. 그녀는 그녀의 손에 들려 있는 것을 보았다. 그녀는 그녀의 아버지가 그 사실을 알고 있었다. 그녀는 그녀의 아버지의 아들을 위해 \n",
            "\n",
            "은 그들 뒤를 따라 나타났다. 그들은 그들에게 들려주는 모습을 보았다. 그녀는 그녀의 손에 들려 있는 그녀의 머리를 부드러운 손 등 위로 올라오는 그녀. 그 말이 떠올랐다.\n",
            "\"... 아.. 아.. 아으으!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "도 몰라도 지금 전에 호위병들을 불렀다. 그래서 그는 그 아이들을 보고 있는 것처럼 보였다.\n",
            "그는 그녀 앞에서 나무 아래로 나타났다.\n",
            "“그는 바로 그 애를 이긴 게 싫어요. 그 애가 그들을 죽이고 있는 사람들의 말이 맞지요?\"\n",
            "\n",
            "\"그렇게 되면 바보 같은 일이다.\"\n",
            "\n",
            "\"그래, 그럴 거야. 그 애는 아직 어렸을 때 그렇게 될 거야. 그 애가 이 사람을 지나 올린 후 \n",
            "\n",
            "달리 역시 그 말에 대해 자기를 도와 줄 생각이 없다면 그 녀석이 이곳에서 태어나지 않았다.\n",
            "\n",
            "\"여기서 우리 모두를 보내야 해요.\"\n",
            "\n",
            "\"그건 그렇게 할 말이 없습니다. \n",
            "\n",
            "가 모두 그 아이를 죽이지 않아. 그리고 그 여자는 마에스터 아에몬이 전부 의원을 잃은 것이 아니었다. 그 때 그녀는 그의 사촌들이 아니었다. 그녀의 가슴에는 그의 한 마리가 사람들을 보고 사랑스러웠다. 그는 그녀를 바라보며 그의 물건을 어루만지며 갑자기 멈춰 섰다. \"저 아이를 보내라고 했어,\" 존이 말했다. \"도대체 무슨 일이 일어났는지 알아야 해요.\" \n",
            "\n",
            "\"그렇게 되면 내가 그의 아들을 돌려주지 않았을 거야.\" \n",
            "\n",
            "\"그래,\" 그녀가 말했다. \n",
            "\n",
            "\"그들은 나의 주인이셨군요,\" 그녀가 말했다. \"당신이 그 아이를 보내 그 아이를 \n",
            "\n",
            "있어요. 그들이 제 아들을 얻었죠. 제 아버지는 여기서 나를 보호하고 싶은 말이오. 나는 그 아이를 해치지 않을 거요. 그 방엔 살아 있는 게 아니오.\"\n",
            "\n",
            "\"네가 그 말을 들으려고 했는데, 이 일에 대해 얘기해 줘야 하는데, 그 애를 위해 용감한 사람이지. 그리고 그 애는 나의 아버지를 죽였어. 그녀는 네 아버지의 아들이고, 그 녀석이 그들의 기분을 증명하지 않았다. \n",
            "\n",
            "'그녀의 아버지는 그가 이 일에 대해 이야기하지 않으실 것이다.\" \n",
            "\n",
            "\"저 여자는 어린 소녀들을 구하러 왔어요.\" \n",
            "\n",
            "\"그는 당신을 보내시오,\" 그녀가 말했다. \"\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            ". 두려움에 떠는 결혼 그였다. 들판은 의사할 전임이었다.\n",
            "\n",
            "'세상에는 경멸이 일곱 달 알 것처럼 절벽 꼭대기를 보내 왔다. 노드 웰더가 롭의 대화를 알 수 있는 것만큼이 묻어라 페티르를 봐모르잖아.\"\n",
            "\n",
            "그는 얼굴을 붉혔다.\n",
            "\n",
            "그러며 루윈이 그렇게 대답하더니 산사의 마음을 거부하면서 서둘러 적군을 안내하러 오는 길에서 월로 방얀   망토를 입었고, 늘씬하게 타오르는 강철 한 점이 되어 있었다.\n",
            "\n",
            "\"안 돼요!\"\n",
            "\n",
            "\"어떻게 어린 소식 때문인지 누구든 상관없어요. 우리가 이미 윈터펠을 잃거든요? 우린 그렇게 하나 보이지 않아. 폭어로는 \n",
            "\n",
            "당신처럼 딸랑이를 놀라고 했어요. 로라스 티렐 경과 그의 기수 사이에서 그녀를 티윈 경에게 무리를 마셔야 하지요. 그들이 세며 죽을 때 한 번이 내 피， 폭풍의 집에서 저물었듯이 뭐라고 일러주었다. 그의 눈은 붉은색 비늘로 조각되어 있었다.\n",
            "·산투를 하옥 드래곤스톤에 대한 얘기는 여기 죽기를 바라는 경우다.\"\n",
            "\n",
            "존은 으르렁대지 못한 채 말을 이었다.\n",
            "\n",
            "\"전하, 나의 정하를 이어야 합니다.\"\n",
            "\n",
            "롭이 어찌나 저 얘기에 대책을 보이지 않겠다는 듯 새롱거리며 말했다.\n",
            "\n",
            "\"여기서야 이곳은 어쩌겠니?\"\n",
            "\n",
            "대니는 조라를 한아래 대기 하지만 그 \n",
            "\n",
            "으로 모든 것으로 자세히 물을 만지고 있었다. \"클로크 가문의 막상에서, 얼마간 멀어졌지.\" \n",
            "\n",
            "\"내겐 로슬레이가 그곳에서, 그가 결혼했을지도 몰라도,\" 캐틀린이 말했다. \n",
            "\n",
            "'그 수염은 그렇지 않으면 거인들이 따뜻하고 햇빛이 암갈색 언덕 아래 모여드는 자신이 잘 알아보기라도 했다면 내 정신을 되찾을 수 있을까요?' 레이디였다. 그는 오른손에 아들을 바라보며 눈을 들었다. \"영주님께서 지금 벌써 행복한 네 방의 방식이 무엇을 하고 있지,\" 서 조라가 웅얼마나 비친 포기를 먹었다. 그녀는 완전히 기쁘게 머리가 묻지 않은 채 아리아는 \n",
            "\n",
            "Epoch 16/20\n",
            "3417/3417 [==============================] - 259s 76ms/step - loss: 1.9206\n",
            "Epoch 17/20\n",
            "3417/3417 [==============================] - 263s 77ms/step - loss: 1.9046\n",
            "Epoch 18/20\n",
            "3417/3417 [==============================] - 264s 77ms/step - loss: 1.8885\n",
            "Epoch 19/20\n",
            "3417/3417 [==============================] - 263s 77ms/step - loss: 1.8725\n",
            "Epoch 20/20\n",
            "3417/3417 [==============================] - 263s 77ms/step - loss: 1.8564\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "지가 그녀의 아버지의 아들이었다. 그녀는 그녀의 아버지의 아들들과 함께 있었다. 그녀는 그녀의 아버지의 아들들이 그의 아들들을 낳아주었다. 그녀는 그녀의 아버지의 아들들이 그녀를 위해 그녀를 데리고 있었다. 그녀는 그녀의 아버지가 그녀의 아버지를 죽였다. 그녀는 그녀의 아버지의 아들들이 그녀를 위해 그녀를 보호하기 위해 그녀를 따라 그녀를 보자 그녀가 말했다. \"그 아이를 죽이려 하는 것이 아니었어. 그는 내가 그 사실을 알아내기 전에 그녀를 죽였어. 그녀는 그녀의 아버지가 그녀의 아버지를 죽였어.’\n",
            "그녀는 그녀의 어깨에 손을 얹었\n",
            "\n",
            "그녀의 아버지의 아들들을 죽였다. 그녀는 그녀의 아버지의 아들이었다. 그녀는 그녀의 아버지의 아들들을 그의 아들들에게 데려가 주었다. 그녀는 그녀의 아버지의 아들이었다. 그녀는 그녀의 아버지의 아들들이 그의 아들들을 낳아주었다. 그녀는 그 사실을 알고 있었다. 그녀는 그녀의 머리카락을 가리키며 그녀를 향해 돌아섰다. \n",
            "\n",
            "\"그렇게 하지 마. 그 아이는 어떻게 되었는지 알아. 그 아이는 어떻게 그런 일이 있었는지 알아. 그 애가 나이트워치의 대원이 되어 가는 것보다 훨씬 더 큰 힘이 있었다. 그는 그들이 그들을 보내 죽은 것을 보았다.\n",
            "\n",
            "였다. 그녀는 그녀의 아버지를 죽였다. 그녀는 그녀의 손에서 머리를 숙였다. \"그녀는 그녀를 죽였어. 그녀가 그녀의 아버지를 죽였어. 그녀는 그녀를 죽였어. 그녀는 그녀의 아버지가 그녀의 아버지의 아들이었다. 그녀는 그녀의 아버지의 아들 중 하나였고， 그녀의 아버지의 아들들은 그들의 아들이 아니었다. 그녀는 그들이 그들을 이끌고 있는 것을 보았다. 그녀는 그 이야기를 들었지만, 그녀의 아버지는 그녀의 아버지가 그녀의 아들이 아니었다. 그녀는 그녀의 아버지의 아들들이 그녀의 아버지를 죽였다. 그녀는 그녀의 아버지의 아들 중 하나였고，\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "그는 그 뒤에 있는 것을 보았다. 그들이 그들의 엉덩이를 대신 움켜잡고 있는 손을 그의 얼굴에 자신의 뺨에 가져다 대어 있던 나를 향해 손을 뻗었다.\n",
            "[정말 아름다운 시녀가 되는 사람들이 있어요.]\n",
            "[네, 전하]\n",
            "자신의 명령에 이곳을 지나치는 나의 몸에 이 모습을 드러내는 그의 모습에 그 이야기를 듣고 있는 그녀가 그녀의 아버지에게 대답을 했다. \"나이트 워치의 대원이 있다고 말하자, 그 때 로드 베릭이 그녀를 불렀다. '그리고 녀석은 나의 이름을 지어주기 전 그녀는 우리의 도시 밑에 있었다. 그녀는 그녀의 손을 잡았다. \"여왕님이\n",
            "\n",
            "릎에는 화려한 금세기가 있었고, 긴 팔은 붉은 색이었다. 그의 손은 그녀의 다리에 부드럽게 그의 가슴을 가렸고, 그의 얼굴은 피부에 붉게 빛나는 턱, 그리고 딱딱한 빵과 사슴 이전의 피부, 주홍색 바탕 사이로 바위스러운 붉은 빛이 보였다. '이제 내가 이미 이 길을 떠나지 못하고 있어.' \n",
            "\n",
            "\"그리고 지금 이 일을 잘 알고 있어.\" \n",
            "\n",
            "\"그럼 아이언 횃불이 그를 죽였다고?\" \n",
            "\n",
            "\"아니, 그의 아들이 그를 죽였다고 생각하시냐?\" \n",
            "\n",
            "\"그래, 로드 에드무레는 그가 아직도 오지 않았어. 그들은 그 다음에 무슨 말을 하는지 알 수 있었다.\n",
            "\n",
            " 아에몬이 그들을 지지하고 있다고 했다. 그녀들은 다른 자신들을 보고 그 사람이 그들을 이끌고 있어.’\n",
            "그녀는 그녀의 손을 잡았다.\n",
            "“그리고 리버룬 출신의 기사들이 그 아이를 죽이고 있었는데, 그 아이는 그가 누군지 알고 있었다. 그는 그의 아들 중 하나였다. 그녀가 그녀에게 불리를 했다. 그녀는 그녀의 손을 잡았다. \"나도 그 빌어먹을 놈들을 보내 주겠어. 그리고 그 애를 혼인시키려 할 때 난 자네를 사랑했어. 그녀는 아직도 그가 돌아가셨을 때 그녀는 죽었다고 생각하지 않았다. 그녀가 그녀에게 그녀를 ‘독살한 모든 사촌이 아니었다\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            ". 에록 께 아네들 역시 가지고 있고, 아버지의 꼬리 둘이잖아요.\"\n",
            "\n",
            "존은 샘의 얼굴에 미소를 지으며 말을 이었다.\n",
            "\n",
            "\"네게 재미있습니다.\"\n",
            "\n",
            "\"전하, 전하께 충성심성문 대가 될 것입니다.\"\n",
            "\n",
            "\"그 화에 싸움에 온 똥처럼 그들이 어디까지 사랑해. 하이 셉톤이 나타나고 싶진 않다고 나의 권력이군.' 서 로버트는 그들이 다시 그녀를 죽인 것을 보고 로드 티윈이 명예롭다는 걸 알고도 충분히 결심했다.\n",
            "\n",
            "\"나는 지금 왕이 되돌아온 대신 천으로, 이 게임을 쓰지 못하게 하는 괴로 기억을 를 배우기 위해 다시 산사 쪽으로 자노스를 휘둘러봤다.\n",
            "\n",
            "실 작정으로 모두 털북적이었다. 기사 하나가 아이언아일랜드 가문들과 비교화하고 물이 나왔다. 친구가 자신의 친구가 되기로 결심했던 그녀의 단 한 번만 알고 있는데요\" ‘\n",
            "하지만 여 왕대비마저 왔어\"\n",
            "호위대장은그의명령을외쳤다.\n",
            "호위대장은 여전히 자신의 음모를 문질렀다.\n",
            "·‘아니요，.\n",
            "“조각배나?\"\n",
            "세르 아리스 오크하트스트 경이 기분 좋게 적의에 살펴보고 있었다. 슬프게도 왕은 그와 정적의를 바친다네라는 말을 들었다. 그는 그보다 좌우면 경썼으며, 왕, 사냥용 격렬한 어릿광대...... 아무리스터 툴리는 피가 꿈을 꾸고 집에서 피가흐르\n",
            "\n",
            "손을 물을 홀대꾸고 싶어하는 사람은 합칠 때마다 그 말을 믿지 못할 색이었다. \n",
            "\n",
            "\"다시 날 살까?\" 나무를 쳐다본 모습을 보았다. 파이크에서 롭을 향해 돌아서 브리엔느를 아리아보다 e퍼트기에 천막으로 강을 걸쳐 나왔다.\n",
            "“불을 지필요. 영주님들이 그를 ‘콰스의 성(城덜하의 환영주동그레윈이라고하시오， 티리온의 태생들 사이로 지나와 ‘사냥!’ 빅타리온이 어머니에 대해 과열하게 속삭였다.\n",
            "·‘다리\t티렐이하셔세고요 봐요. 이 다리의 시체를 먹어 보시도록 말입니다.\" \n",
            "\n",
            "헛파이가 그 꽃을 받아 들어왔을 때, 하던 개들이 오른손으로 물위를 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "source": [
        "You can download a large amount of generated text from your model with the cell below! Rerun the cell as many times as you want for even more text!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "source": [
        "You can download the weights and configuration files in the cell below, allowing you recreate the model on your own computer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "source": [
        "To recreate the model on your own computer, after installing textgenrnn and TensorFlow, you can create a Python script with:\n",
        "\n",
        "```\n",
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='colaboratory_weights.hdf5',\n",
        "                       vocab_path='colaboratory_vocab.json',\n",
        "                       config_path='colaboratory_config.json')\n",
        "                       \n",
        "textgen.generate_samples(max_gen_length=1000)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=1000)\n",
        "```\n",
        "\n",
        "Have fun with your new model! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Zjtsb_Dgj-",
        "colab_type": "text"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the model fails to load on a local machine due to a model-size-not-matching bug (common in >30MB weights), this is due to a file export bug from Colaboratory. To work around this issue, save the weights to Google Drive with the two cells below and download from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-IzscxUHmAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR4_XJpfKAIn",
        "colab_type": "code",
        "outputId": "f70ce499-1062-4968-8423-c7dbcd71cc5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "uploaded = drive.CreateFile({'title': '{}_weights.hdf5'.format(model_name)})\n",
        "uploaded.SetContentFile('{}_weights.hdf5'.format(model_name))\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1b6T6M32YnXs-c0NB-PEi6MhAdCuG7RHy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "source": [
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}